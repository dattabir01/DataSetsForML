{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19 Revision and Completion  of activity Detection and TRANSFER LEARNING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMa19O6dnHxlVc8uKOQim9u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/DataSetsForML/blob/master/19_Revision_and_Completion_of_activity_Detection_and_TRANSFER_LEARNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7PUz0znBOfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will use a hardcoded video as test data\n",
        "# if doing on laptop you can even use webcab for same program \n",
        "# as input stream \n",
        "\n",
        "# inputs were hardcoded,video is not a user input but an mp4 or avi file\n",
        "\n",
        "# Algorithm\n",
        "# 1. Input a video (or live stream)\n",
        "# 2. open the frames as images\n",
        "# 3. Run object detection on images to understand continous usage of objects (RESNET/VGG)\n",
        "# 4. Continous usage of objects is called ACTIVITY\n",
        "# 5. in each frame of video, classify the frame as an activity\n",
        "# 6. combine the frames back into a video to deliver as classified output! \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd5QlZ0FEjHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## start of: TRAIN.py\n",
        "\n",
        "# WHEN DEVELOPING-> import only when required\n",
        "# - minimize program size - control over 3rd party components\n",
        "# WHEN in production-> include all libraries in the beginning of program \n",
        "# itself\n",
        "# - minimize LATENCY - all mandatory components should be available before \n",
        "# execution starts \n",
        "# Sometimes all libraries are written in a single config or dependency\n",
        "# or include file\n",
        "# this is just to minimize \"typing\" size, no impact on program because\n",
        "# while execution, your library will be copy-pasted with its source. \n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pickle # to read/write binary files as dumps (for weights and biases or binarized labels)\n",
        "import cv2\n",
        "import os # os.separators to separate path names and get file name and file folder name\n",
        "from keras.applications import ResNet50\n",
        "# to customize models with own layers\n",
        "from keras.layers.core import Flatten, Dropout, Dense\n",
        "from keras.layers.pooling import AveragePooling2D # AVERAGE pixel -> do this when color of object shouldn't matter \n",
        "from keras.layers import Input # input layer can take general or any input size (dynamic input size but once decalred cannot be changed)\n",
        "from keras.models import Model\n",
        "#label binarizer to encode/decode binarized outputs \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import imutils\n",
        "from imutils import paths\n",
        "# but what if i wanted to take average without losing channels?\n",
        "# Conv2D -> GlobalAveragePooling-> Conv2D would split data into R, G and B channels \n",
        "# then GAP will calculate averages for R, G, and B separately thus preserving colors \n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xU9AiEvE4Qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variables that should have been collected from user through UI or command line or API post\n",
        "dataset = 'data'\n",
        "model_path = 'bin'\n",
        "binarizer_path = 'bin'\n",
        "evaluation_path = 'eval'\n",
        "test_path = 'test'\n",
        "# directory structure required\n",
        "# myactivitydetector.py --dataset data --bin bin --eval-data eval --test-data test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heEmQnzIHa_T",
        "colab_type": "code",
        "outputId": "d73b2680-e3d6-4365-98c2-17f921a524ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# shuffle the data after reading all paths\n",
        "\n",
        "imagePaths = sorted(list( paths.list_images(dataset)))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        "imagePaths[:2]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/weightlifting/00000147.jpg', 'data/hockey/00000009.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R3or1VFHsVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to conver to img_to_array and resize \n",
        "# this is how to use ResNET \n",
        "# in our VGG-> we took (96,96,3)\n",
        "# larger images are required because smaller image= not enough filters possible\n",
        "label_names = [\"weightlifting\",\"swimming\",\"hockey\",\"basketball\"]\n",
        "labels = []\n",
        "data = []\n",
        "for path in imagePaths:\n",
        "  label = path.split(os.path.sep)[-2] # folder name! to represent class name \n",
        "  if label not in label_names:\n",
        "    continue\n",
        "  labels.append(label)\n",
        "  img = cv2.imread(path)\n",
        "  # ResNet requires this to be done- rearranging the channels and making sure its R,G,B in this format and not B,G,R\n",
        "  # ImageNet-> means -> separate means for R,G,and B!!! their channel positions are also hardcoded!\n",
        "  # so if this was not done to an image, the logic of R will be applied to B and vice versa!! \n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # these are simple reshape, resize and expand_dims functions\n",
        "  img = cv2.resize(img, (224,224)) \n",
        "  data.append(img)\n",
        "  # RESNET model -> input size (224,224,3) , only accept RGB channel, while most images\n",
        "  # like jpeg, png, jpg, giff are arranged in BGR (just opposite)\n",
        "  # Object detection -> there order of the color did  not matter because RGB values combined would have \n",
        "  # resulted in same color anyway \n",
        "  # just in case error handling-> if image is already RGB, the below function will do nothing, if its BGR, it will\n",
        "  # be converted to RGB \n",
        "  \n",
        "  # they readjust dimensions to fit various frameworks \n",
        "  # RESNET doesn't require image aug sep because it was inbuilt into its architecture \n",
        "  # aug.flow-> model.fit_generator \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gmybBVnJ_-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "lb = LabelBinarizer() # LABELS were converted into 1-hot matrices instead of label encoded (categorical label data) \n",
        "# if one-hot columns on input data-> ONE-HOT encoding (it generates new columns out of categorical input data)\n",
        "\n",
        "# 5 encoding-> LabelEncoders, One-Hot, Multi-Hot, LabelBinarizer, Word2Vector \n",
        "# Label Encoder-> no statistical relationship between data, and only positional representation was required\n",
        "#        Sentiment Analysis, Topic Understanding, Encryption/Decryption, Language/Machine translation \n",
        "#        Preserves word as a token, not meant for categorical data (but can be used in simple binary classification 0-1)\n",
        "\n",
        "\n",
        "# Customer_problem     Category_problem    SolutionSuggested (label)\n",
        "# lost my card          card-related             CardsTeam \n",
        "# missed my EMI         loan-related            LoansTeam\n",
        "# new credit card       card-related            CardsTeam\n",
        "# random deductions     card-related            Security Team       \n",
        "\n",
        "# customer problems are continous english statements -> for their encoding I have 2 choices \n",
        "#        Label Encoding, Word2Vector \n",
        "# category problem is an input categorical column (all values are INDEPENDET of each other within a column). This \n",
        "#       column should ideally be used for filtering. The best way of filtering with minimal programming-> one-hot encoding \n",
        "# Solution suggested is the LABEL or output. For its encoding I have 2 choices\n",
        "#        label encoder, Label Binarizer \n",
        "# If it is a prediction-on-input problem, like autocomplete, spell check, sentence completion, word prediction \n",
        "# I need a VECTORS capable of changing vectors when word is used in various positions and sequences \n",
        "\n",
        "# how do i select length or granularity of these vectors? Should be they sentence, words, characters, pages? \n",
        "# what shold be the segmentation size?\n",
        "# WHEN USING PATTERNS FOR PREDICTION-> large patterns detect small objects, small patterns detect large object\n",
        "# Smallest pattern in string is a CHARACTER\n",
        "# that's why character level Seqence-2-sequence mapping is preferred \n",
        "\n",
        "# when encoding \"I am going home\"\n",
        "# I's vector is independent-> because it is starting vector\n",
        "# but the vector for 'o' on 7th position and 13th position is built up of sequences just before them \n",
        "# the 7th position's vector has been calculated wrt 'I am go' and not just 'o' alone. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# LABEL BINARIZER is MATHEMATICALLY massively more optimized and faster to calculate than other data structures\n",
        "# MATRICES -> very close to NUMPY and thanks to numpy, their operations are very fast in most languages \n",
        "# Label Encoding CANNOT be used for MULTI-CLASSIFICATION but Label Binarizer can be! multiple columns hot on a single\n",
        "# row indicate multiple classification:   [ [1 0 1], [0 0 0], [ 1 0 1]] (multi columns hot)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# One-hot and Multi-hot encoding -> ONLY on INPUT categorical data. Why not regression? Because it will take all \n",
        "#        unique values, and make them columns! It is very likely that most values are unique!!! \n",
        "#        Sales predictions (region specific), FILTERING of input data, wherever input categories were independent of \n",
        "#         each other (profits in Russia cannot be predicted the same way as Europe!)\n",
        "#        Onehot or multi-hot encode-> FILTER the data or let weights be considered as 0 -> do individual learning on\n",
        "#         each encoded category seperately \n",
        "#        It is NOT used for word or char or sentence tokens! \n",
        "\n",
        "# Label Binarizer -> ONLY on OUTPUT (labelled) categorical data. Why not regression? same reason as one-hot encoded \n",
        "#         Scenarios to use it: When output categories are independent of each other, and input may carry more than\n",
        "#         one output (an image can contain multiple objects that can be detected)\n",
        "#         Object detection, activity detection, advanced multi-class classifications\n",
        "#         DIFF from One-hot-> done on output not input, does not create new columns in\n",
        "#                             dataset-> creates new columns in matrix instead\n",
        "\n",
        "\n",
        "\n",
        "labels = lb.fit_transform(labels)\n",
        "labels # HOT-encoded MATRIX \n",
        "(xtrain, xtest, ytrain, ytest) = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42 )\n",
        "# << left shift operation\n",
        "#       0 0 0 1  0 0 0 0   -> left shift by 2 - >   0 1 0 0 0 0 0 0 \n",
        "#          -> right shift by 1 -> 0000 1000 \n",
        "# This label binarizing is EXTREMELY FAST because of LEFT shift operations which happen at bit-level \n",
        "# there is no need to go through the entire list of items, just need to know HOW many items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aath-DKpKGXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into train/test\n",
        "# whenever we need classes balanced while splitting, we use a process called 'stratification'\n",
        "# it shuffles on the basis of types of output labels, and not just random_state\n",
        "(xtrain, xtest, ytrain, ytest) = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZXaD49nMPXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainAug = ImageDataGenerator(rotation_range=25, zoom_range=0.20, width_shift_range=0.2, height_shift_range=0.2, \n",
        "                              shear_range=0.20, horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "valAug = ImageDataGenerator() # default augmentation (everything is set to false-> no augmentation)\n",
        "# this will help validate the model in 2 augmentation- one with our v/s with any other option! \n",
        "# these values are for R, G and B respectively. This is the reason why we had to make sure all images are \n",
        "# only RGB and not BGR. Else wrong mean values would have been considered for loss calculation. \n",
        "means = np.array( [ 103.939, 116.779, 123.68 ])\n",
        "trainAug.mean = means\n",
        "valAug.mean = means \n",
        "# deviations will be calculated from respective means\n",
        "# train data -> trainaug.means\n",
        "# valdata -> valAug.means \n",
        "\n",
        "# Since the data is augmented and no longer the original image, the difference between the original image (no aug- val)\n",
        "# and augmented image (trainAug) can be calculated as difference in the mean \n",
        "# when using keras.application \n",
        "# To find out this mean there are various formula, but we are going to use the preferred production method-\n",
        "# WITH RESNET and VGG, we use means from 'ImageNet'. \n",
        "# 3 averages-> 1 each for R, G and B \n",
        "# From scratch way is to calculate it based on your data. BUT, when doing transfer learning, follow what model\n",
        "# says. VGG and Restnet for 'ImageNet' standards. \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUih1xP-UK4A",
        "colab_type": "code",
        "outputId": "d777acde-e54d-4a02-fe25-2d7b998c269a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "# LAST time-> we built our own PandaVGG, THIS time-> transfer learning using ResNet \n",
        "# Last time-> we calculated our weights for PandaVGG, THIS TIME-> preserved ResNet's weights by setting \n",
        "# non trainable layers \n",
        "# REST of it is EXACTLY the same except hyperparameters \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# cloud -> hadoop (parquet) -> g(s3) -> no bigquery\n",
        "# PySpark notebooks -> external tables -> DataBricks \n",
        "# Transfer learning and build our model on top of it\n",
        "basemodel = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "# include top = False -> i am going to provide my own top-layers, the default ResNet top layers are not requried\n",
        "# (top layers are the ones on right)\n",
        "# name: Left side of model is called BASE or BOTTOM, the right side of model is called a HEAD or TOP\n",
        "\n",
        "# if i am importing my weights from ImageNet-> then during learning, all this will be recalculated and transfer-learning\n",
        "# will be lost!!!! That is why, when Transfer Learning, ALWAYS make sure that transfered layers' learning is set\n",
        "# to false \n",
        "\n",
        "# activity detection and classification model\n",
        "# use object detection as base algorithm and build your own algo on top of it \n",
        "# basemodel was loaded as KNOWLEDGE, myModel is the 'Head' or 'Top' model \n",
        "myModel = basemodel.output # TRANSFER LEARNING (Knowledge transfer) is done \n",
        "# another of adding layers besides model.add\n",
        "# MATMUL way -> multiplicative way of adding layers (because anyway between layers its the mul, inside layers-> add)\n",
        "# model  = (additive_layers)(model)\n",
        "# MATMUL is nump matrix multiplication \n",
        "# NEURAL -> playing with TENSORS-> only 2 ops-> Add (inside a layer), Mul (between the layers) \n",
        "myModel = AveragePooling2D(pool_size=(7,7))(myModel) # in matmul AXB != BXA, same as model.add(AvgPool2D)\n",
        "#Pattern recognition \n",
        "# till now my data is 2 d! Image Pattern Recog\n",
        "# Flatten -> Dense(ReLu) -> Dense (Softmax)\n",
        "\n",
        "\n",
        "# a= a+b, a+=b <- diff methods of doing the same thing\n",
        "# a++, a=a+1\n",
        "\n",
        "# Add, Mul -> y = weights*x + bias \n",
        "# y = w1*x1 + w2*x2 + w3*x3 + bias \n",
        "\n",
        "# model.add () -> this is not addition, this means add the layer next to it (which would be multiplication)\n",
        "\n",
        "\n",
        "\n",
        "# ways to add layers in Keras\n",
        "# 1. Model.add\n",
        "# 2. MatMul way -> either add inside layer or multiply between layers \n",
        "# 3. Class Derivation -> SIMILAR approach to what we did with VGG except this also includes Inheritence \n",
        "# from keras' model class \n",
        "\n",
        "#class MiniVGGNetModel(Model):\n",
        "#\tdef __init__(self, classes, chanDim=-1):\n",
        "#\t\t# call the parent constructor\n",
        "#\t\tsuper(MiniVGGNetModel, self).__init__()\n",
        "\n",
        "\n",
        "# https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/\n",
        "\n",
        "myModel = Flatten(name='flatten')(myModel) # specific names to layers, you can do so by name property\n",
        "myModel = Dense(512, activation='relu')(myModel)\n",
        "myModel = Dropout(0.3)(myModel) # regularization- to avoid overfitting \n",
        "myModel = Dense(len(lb.classes_), activation='softmax')(myModel)\n",
        "\n",
        "# what are the various ways to avoid overfitting?\n",
        "# 1) REGULARIZATION -> L1, L2, Dropout, Early Stopping (Median, Bandit, Truncation, Patience) [manual initially, but best automated]\n",
        "# 2) bias-variance tradeoff (adjust the values) [automated]\n",
        "# 3) hyperparamter tuning (adjust the values) [Grid Search, Random Search]\n",
        "# 4) Data Augmentation (word2Vectors, Noise, Image Augmentation, image overlays, filters, video mixers) (manual)\n",
        "# \n",
        "\n",
        "# Early stopping -> tf provides patience-> this is the continuous epochs for which a model will perform poorly \n",
        "# Better strategies-> RUN multiple algorithms in parallel, and early stop COMPARITIVELY poor performing algorithms\n",
        "#      1) MEDIAN early termination: FIND out the average performance of all algorithms, and terminate all below the \n",
        "#                 median performance (example: 30%, 40, 60, 62, 63). Here median is 60, so the first 2 algos are dropped\n",
        "#                 # YES, these are repeated and median keeps shifting \n",
        "#      2) TRUNCATION policy: tf patience style- based on absolute performance measure for a continous time period\n",
        "#                 example: threshold was 80%, and perfor: 30%, 40, 60, 62, 63, then all algos would be dropped!!!\n",
        "#      3) BANDIT policy-> over here the minimum performance threshold is set by us. All algos performing below it will\n",
        "#                 be terminated -> truncation's problem solved-> instead of absolute threshold, a dynamic threshold \n",
        "#                 is calculated. \n",
        "\n",
        "# most human effort should be focused on 3 and 4 \n",
        "# 1 and 2 can be automated, and there are many algorithms that will do it better than we can \n",
        "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters \n",
        "\n",
        "# HPs are Learning Rate, Epochs, Layers, hidden dimensions, number i can play around with and change model \n",
        "# performance \n",
        "# less or more data-> HP tuning is ALWAYS required \n",
        "# Hyperparameter tuning is painful task-> INFINITE POSSIBLE COMBINATIONS that could have been used\n",
        "# there is NO perfect answer in some cases! \n",
        "# Quest is to find either the BEST answer or a WORKABLE answer \n",
        "# if you want to find best answer, then the search-space for hyperparams has to be finite (SARIMAX=> (1,0,1,1)X(0,1,1))\n",
        "# Grid Search is to find best answer \n",
        "# it creates an EXHAUSTIVE truth table generating ALL combinations of Hyperparams, so just choose Min or Max \n",
        "\n",
        "# Random Search is to find workable, but not the best paramters- idea is to find something quickly \n",
        "# and move on -> it is done wherever Hyperparameter search space is INFINITE \n",
        "# Example: In most cases!!!! Grid search is exhaustive, time consuming and sometimes very expensive on big data\n",
        "# some grid search calculcations (enc/dec) can cross 1 BILLION years of computer/math time to calculate\n",
        "\n",
        "\n",
        "# in Resnet-> the mean values taken from ImageNet are global standards. So i as user will not be able to calculate\n",
        "# better means, because for that i will require all images on internet!!! \n",
        "# Global standards -> average for R,G and B are different (of course!)\n",
        "# if i change the positions of channels, than Blue channel could have got divided by mean from green channel which \n",
        "# would defeat the purpose of calculating mean from global data!!!!\n",
        "\n",
        "# in PandaVGG that we built-> we just mantained it via Channel Dimension = channels_first or _last\n",
        "# after that-> we calculated our averages per layers and didn't worry about whether it was RGB or BGR or any other format\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Model(inputs=basemodel.input, outputs=myModel) # connection of the two pipes -> ResNet and Mymodel \n",
        "\n",
        "for layer in basemodel.layers:\n",
        "  layer.trainable = False \n",
        "# Learning will be ONLY for myModel not for basemodel-> resnet weights will be preserved, while myModel will keep \n",
        "# learning \n",
        "# PARTIAL LEARNING-> some part of model is already smart, some part is learning from it's smartness \n",
        "\n",
        "\n",
        "\n",
        "# IF NOW YOU WANT MODEL TO BE FAMILIAR WITH YOUR IMAGES, you need to show images again!\n",
        "# but this brings us a problem- if i retain the model -> then the imagenet weights will be recalculated!\n",
        "\n",
        "# every time back-prop -> weights and bias are recalculated\n",
        "# everything that i inherited from resnet will GO AWAY except its shape!!\n",
        "# TO PRESERVE THE WEIGHTS INHERITED you can set that layers will NOT be learnt upon\n",
        "# thAT means their parameters will be unaffected by gradient descent \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbLvqfL7cBoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}